{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T19:15:16.782673Z",
     "start_time": "2023-07-21T19:15:16.204316Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T19:15:16.790893Z",
     "start_time": "2023-07-21T19:15:16.785104Z"
    }
   },
   "outputs": [],
   "source": [
    "def project(word, dimension):\n",
    "    \"\"\"\n",
    "    Returns the scalar projection of word on dimension. Word and dimension are both assumed to be vectors\n",
    "    \"\"\"\n",
    "    result = round(np.dot(word, dimension)/ np.linalg.norm(dimension), 3)\n",
    "    return result\n",
    "\n",
    "def doPCA(words_start, words_end):\n",
    "    \"\"\"\n",
    "    Performs PCA on differences between pairs of words and returns the first component\n",
    "    Based on function doPCA in Bolukbasi et al. (2016) source code at https://github.com/tolga-b/debiaswe/blob/master/debiaswe/we.py\n",
    "    Parameter\n",
    "    ---------\n",
    "    words_start : list\n",
    "        List of hashed words at one end of interested dimension\n",
    "    words_end: list\n",
    "        List of hashed words at the other end of dimension\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        First component of PCA of differences between pairs of words\n",
    "    \"\"\"\n",
    "    matrix = []\n",
    "    for i in range(len(words_start)):\n",
    "        center = (words_start[i] + words_end[i])/2\n",
    "        matrix.append(words_end[i] - center)\n",
    "        matrix.append(words_start[i] - center)\n",
    "    matrix = np.array(matrix)\n",
    "    # cannot have more components than the number of samples\n",
    "    num_components = len(words_start)*2\n",
    "    pca = PCA(n_components = num_components)\n",
    "    pca.fit(matrix)\n",
    "    return pca.components_[0]\n",
    "\n",
    "def build_dimension(words_start, words_end):\n",
    "    \"\"\"\n",
    "    This method builds a dimension defined by words at separate end of a dimension.\n",
    "    Multiple methods exist in previous literature when building such a dimension.\n",
    "    1) Kozlowski et al. (2019) averages across differences between different word pairs, noted to be interchangeable with averaging words on each side of the dimension and\n",
    "    then taking the difference between averages. They are empirically verified to be identical.\n",
    "    2) Bolukbasi et al. (2016) defines gender direction using a simple difference between man and woman in the corresponding tutorial. In the same tutorial, \n",
    "    racial direction is defined as difference between two clusters of words that are each sum of the embeddings of its corresponding dimensions\n",
    "    normalized by the L2 norm. Wang et al. (2020) note that normalization is unnecessary. If unnormalized, this method should be equivalent to #3.\n",
    "    3) Bolukbasi et al. (2016) defines gender direction also by taking the differences across multiple pairs, doing PCA on these differences, and \n",
    "    taking the first component as the gender direction.\n",
    "    Parameter\n",
    "    ---------\n",
    "    words_start : list\n",
    "        List of vectors at the positive end of the dimension, where positive implies more likely to affect identification positively\n",
    "    words_end: list\n",
    "        List of vectors at the other end of dimension\n",
    "    Returns\n",
    "    -------\n",
    "    (mean_dim, pca_dimension) : 2-tuple of numpy vector\n",
    "        Two vector that represents the dimension of interest calculated using method #1 and #3.\n",
    "    \"\"\"\n",
    "    assert len(words_start) == len(words_end)\n",
    "    differences = [(np.array(words_start[i]) - np.array(words_end[i])) for i in range(len(words_start)) if not np.isnan(words_start[i]).any() and not np.isnan(words_end[i]).any()]\n",
    "    mean_dim = np.array(differences).mean(axis=0)\n",
    "    pca_dim = doPCA(words_start, words_end)\n",
    "    if project(words_start[0], pca_dim) < 0:\n",
    "        # convention used in the current script is that words_start should represent the positive dimension\n",
    "        pca_dim = pca_dim * -1\n",
    "    return (mean_dim, pca_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T19:15:52.966633Z",
     "start_time": "2023-07-21T19:15:16.792228Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import gensim.downloader as api\n",
    "\n",
    "model = api.load(\"word2vec-google-news-300\")\n",
    "gender_words = [['she', 'her', 'woman', 'Mary', 'herself', 'daughter', 'mother', 'gal', 'girl', 'female'],\n",
    "                ['he', 'his', 'man', 'John', 'himself', 'son', 'father', 'guy', 'boy', 'male']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T19:15:52.972924Z",
     "start_time": "2023-07-21T19:15:52.969038Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_dim, pca_dim = build_dimension([model[word] for word in gender_words[0]], [model[word] for word in gender_words[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T19:16:35.426516Z",
     "start_time": "2023-07-21T19:16:35.422692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accountability : 0.039\n",
      "speed : -0.227\n",
      "integrity : -0.164\n",
      "community : 0.207\n",
      "compassion : 0.216\n",
      "diversity : 0.327\n",
      "teamwork : -0.251\n",
      "empathy : 0.092\n"
     ]
    }
   ],
   "source": [
    "values = ['accountability', 'speed', 'integrity', 'community', 'compassion', 'diversity', 'teamwork', 'empathy']\n",
    "for word in values:\n",
    "    r = project(model[word], pca_dim)\n",
    "    print(f'{word} : {r:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
