{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T17:55:25.037463Z",
     "start_time": "2023-08-02T17:55:25.028746Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "\n",
    "#data = pd.read_csv(\"/Users/Lara/Dropbox/LanguageGender/Data/Advocates/Cleaned/responses_linguistic_measures.csv\")\n",
    "data = pd.read_csv(\"/Users/Lara/Dropbox/LanguageGender/Data/Advocates/Cleaned/cleaned_Advocates_Community.csv\")\n",
    "response2exp_rating = {}\n",
    "response2intro_q1 = {}\n",
    "response2intro_q2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T18:09:06.607466Z",
     "start_time": "2023-08-02T18:09:06.480792Z"
    }
   },
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "The model `gpt-4` does not exist or you do not have access to it. Learn more: https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [136]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         response2intro_q2[rid] \u001b[38;5;241m=\u001b[39m creativity\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mrate_single_response\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mi am so tired\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [136]\u001b[0m, in \u001b[0;36mrate_single_response\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrate_single_response\u001b[39m(text):\n\u001b[1;32m      5\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease rate the creativity of this response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msys_message\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     creativity \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m creativity\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    220\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    221\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    222\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[0;32m--> 230\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    617\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    618\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    619\u001b[0m         )\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    621\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 624\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    688\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    689\u001b[0m     )\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: The model `gpt-4` does not exist or you do not have access to it. Learn more: https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4."
     ]
    }
   ],
   "source": [
    "sys_message=\"\"\"We would like you to help us with rating the text responses from a survey we ran. Your task will be to determine the extent to which each responses use creative language. \n",
    "Please provide a whole number on a scale of 1 to 5, with 1 being the least creative and 5 being the most creative. Provide the number only without additional explanations.\"\"\"\n",
    "     \n",
    "def rate_single_response(text):\n",
    "    message = f\"Please rate the creativity of this response: {text}\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_message},\n",
    "            {\"role\": \"user\", \"content\": message},\n",
    "        ]\n",
    "    )\n",
    "    creativity = response['choices'][0]['message']['content']\n",
    "    return creativity\n",
    "\n",
    "def gpt_creativity(row, data_fmt='row'):\n",
    "    rid = row['ResponseId']\n",
    "    if rid not in response2exp_rating:\n",
    "        creativity = rate_single_response(row['text'].replace('\\n', ' '))\n",
    "        response2exp_rating[rid] = creativity\n",
    "    \n",
    "    if rid not in response2intro_q1:\n",
    "        creativity = rate_single_response(row['Intro.Question.1'].replace('\\n', ' '))\n",
    "        response2intro_q1[rid] = creativity\n",
    "    \n",
    "    if rid not in response2intro_q2:\n",
    "        creativity = rate_single_response(row['Intro.Question.2'].replace('\\n', ' '))\n",
    "        response2intro_q2[rid] = creativity\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T18:05:58.212115Z",
     "start_time": "2023-08-02T18:05:20.762446Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347f50686b8046f7af73f92abd26f254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "for i in tqdm(range(len(data))):\n",
    "    gpt_creativity(data.loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T18:07:57.727250Z",
     "start_time": "2023-08-02T18:07:57.721217Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R_3ndyllvIu6WM6cd': '4',\n",
       " 'R_2CVeTUOGwBm5GQK': '3',\n",
       " 'R_1pVRkbEWOgPiG4B': '3',\n",
       " 'R_1kMpH1Xrc0Ex3tS': '4',\n",
       " 'R_3k6x7aIAXCKpko8': '3',\n",
       " 'R_ZyHhLalU2o16PKN': '3',\n",
       " 'R_2vhPg3PWjmX8rgw': '3',\n",
       " 'R_278U8FOi3tN4fb7': '3',\n",
       " 'R_3QRkUp2d3LCwHFn': '3',\n",
       " 'R_247WAg6XOasetNU': '3',\n",
       " 'R_NVJlNVaDMSDDEkh': '3',\n",
       " 'R_1M4mRT81DBwuQDR': '4',\n",
       " 'R_RReOOHNp8gPECqJ': '4',\n",
       " 'R_2X0weJKAdGfyo1s': '4',\n",
       " 'R_vxkPMkxgu1BNrgd': '3',\n",
       " 'R_1KW7inJBZ9cr73z': '4',\n",
       " 'R_1d7iMBD2tpENW1z': '4',\n",
       " 'R_2EgHewqrHy4J6v7': '4.',\n",
       " 'R_2CHRfBSuwGRe8OO': '3',\n",
       " 'R_2rNIekkgAjK2VXS': '2',\n",
       " 'R_2xPg8rkCknHy9Ri': '4',\n",
       " 'R_D1vSNHbegtR3VsZ': '4',\n",
       " 'R_XKPIzJFDt65Zgo9': '4',\n",
       " 'R_27WL4Go78QAUhRh': '3',\n",
       " 'R_2qENeIoDt93hg8a': '2',\n",
       " 'R_2v8S9LROEchRBQr': '3',\n",
       " 'R_rqzMe7kYnjk3uTL': '4',\n",
       " 'R_Y9tQARSXThgkO0V': '4',\n",
       " 'R_247NMQlG7gBX3mI': '3',\n",
       " 'R_1DCIO8lk1GThfkX': '4',\n",
       " 'R_6tzaz1LfAzgHoXf': '2',\n",
       " 'R_3nCcB4ALJnFZgln': '3',\n",
       " 'R_1mlUBrqmYCd88B7': '3',\n",
       " 'R_RCUgtTCi95KR5n3': '4',\n",
       " 'R_6u3NZSjSDxawBQl': '4',\n",
       " 'R_2VpX0RMURPS4rlW': '3',\n",
       " 'R_3CWd1FZK8cqYeAN': '2',\n",
       " 'R_1GUhw7iGp3VPjAp': '4',\n",
       " 'R_1jptJMu8HjZRrQ6': '3',\n",
       " 'R_1FJnmsveS9htwIb': '2',\n",
       " 'R_3DbYrglsLTpxbcD': '4',\n",
       " 'R_1LuL8MV9VJLGJ6K': '2',\n",
       " 'R_3DwIgmpENTuPNhp': '4',\n",
       " 'R_1obfTyPyDzdgTlp': '4',\n",
       " 'R_2WSeeyWN4IQB0ce': '3',\n",
       " 'R_4IV19EKSdBUnbJ7': '3',\n",
       " 'R_2e8p3K6fbleEWL0': '3',\n",
       " 'R_2c2G6Ei5czSz1X5': '3',\n",
       " 'R_31pH5UMbUvnZSGZ': '4',\n",
       " 'R_12xwqQkl7tmNa1M': '2',\n",
       " 'R_vwyy5CPvAYXlv45': '4',\n",
       " 'R_3DdbKWJbWtIES83': '3',\n",
       " 'R_POGIbbbx50odP7H': '4',\n",
       " 'R_3PQOATffIJ7p0Tz': '2',\n",
       " 'R_33ewfF21r5S9dfJ': '3',\n",
       " 'R_3EfMuXPSzAgRWeW': '4',\n",
       " 'R_2eWmfu5x8Kr8Ul1': '5',\n",
       " 'R_cIPOQkqporMpdkt': '3',\n",
       " 'R_2qmwiFplCv1ZqIO': '4',\n",
       " 'R_1ImBDwl1s3nRcli': '5',\n",
       " 'R_1LG6Uf3azY4a9Bn': '4',\n",
       " 'R_270ZUAHD2JdQIue': '3',\n",
       " 'R_dpxSS6fBANtzJjr': '5',\n",
       " 'R_1gtJYd3jwDoPF43': '5',\n",
       " 'R_1N2hnxX01kZFfcu': '3',\n",
       " 'R_u4yJyLIaBTPIRz3': '4',\n",
       " 'R_4SjbMMlMuc7mGWd': '4',\n",
       " 'R_1pEiqlZdVDOl0QT': '4',\n",
       " 'R_25tR1C6DHSosX4P': '3',\n",
       " 'R_afuP1faTbl1cVlT': '3',\n",
       " 'R_2usTno6yACQqDlE': '2',\n",
       " 'R_3RguaLz4K5GDOHV': '3',\n",
       " 'R_24GElpCw3shzXwy': '2',\n",
       " 'R_1ongYh7YdMAD7nV': '4',\n",
       " 'R_20Ool39oqqHZxCs': '3',\n",
       " 'R_2f7GmNqv0nNVD91': '4',\n",
       " 'R_2AHlHW7cVJg4grD': '5',\n",
       " 'R_2TpZlJKbYkXNrdi': '4',\n",
       " 'R_1faa6qIv6UgQuis': '3',\n",
       " 'R_1mpWesNhnTFmzrI': '4',\n",
       " 'R_2TXcaYiQuM6VwIo': '3',\n",
       " 'R_3DhVXWxFzrUFaYt': '4',\n",
       " 'R_Dic4dbuw7NXCSqZ': '4',\n",
       " 'R_27wG8vYQWLUY834': '4',\n",
       " 'R_1lt0e5U0CV9h8a1': '4',\n",
       " 'R_3M4YT9ihbpgw4Qt': '3',\n",
       " 'R_pyHkKEe50uxgfsJ': '2',\n",
       " 'R_qUywX0YZkYwFBKh': '4',\n",
       " 'R_2usxuh7BCre1R9w': '3',\n",
       " 'R_2YoarrO5bVY2Xgf': '1',\n",
       " 'R_2tsRrRxderwxFnD': '5',\n",
       " 'R_1ozHw5fcvE7AVlJ': '2',\n",
       " 'R_3kzVJIkNqHt0EHV': '3',\n",
       " 'R_2uIgmXRHQHZiGM3': '3',\n",
       " 'R_3qEyPumWlgXr0rW': '4',\n",
       " 'R_3g65mQQGiy72svx': '3',\n",
       " 'R_1ob4dVzmMTzeBbO': '3',\n",
       " 'R_3hDO8q3Jt7a2Hje': '2',\n",
       " 'R_2rZ81umlmHYnrNZ': '2',\n",
       " 'R_2SJr0llQ9y2Vgu9': '3',\n",
       " 'R_3hDroYj98wQDay9': '3',\n",
       " 'R_1jPAgFrfW8NOLLC': '4',\n",
       " 'R_27esoydm32jxH9N': '3',\n",
       " 'R_3DcL8Y7BA0elAew': '2',\n",
       " 'R_DqHKEnCQ1s7XyzD': '3',\n",
       " 'R_DPmiPC7xzxeCkP7': '3',\n",
       " 'R_ag8VtaBJGfqMbBv': '4',\n",
       " 'R_297aiYR1mrqvSwt': '4',\n",
       " 'R_1GVA8m1wiesjNpH': '3',\n",
       " 'R_21zjTEdAT1WpTmI': '4',\n",
       " 'R_AmHB8fQkKuuBdbH': '2',\n",
       " 'R_1rqPbiJ1z3e4siK': '4',\n",
       " 'R_3q8VoE33EprSUra': '5',\n",
       " 'R_3kMlRRy6akXD5JE': '4',\n",
       " 'R_25Xdl7rTVaV22QY': '3',\n",
       " 'R_3iBUJyzXolN0qy6': '4',\n",
       " 'R_SHMYiVZQsJnGqYh': '3',\n",
       " 'R_Cfs5byz0w4bBLrP': '3',\n",
       " 'R_4NtpVptkmd0cEyB': '2',\n",
       " 'R_2w7B7WEAVfe1sl6': '3',\n",
       " 'R_2EidiVXDEBADdVI': '4',\n",
       " 'R_2QSNYmbE0ZMhyhB': '4',\n",
       " 'R_2PcDtcf4JI9RPqJ': '3',\n",
       " 'R_3r1aCS9spXO6p6Z': '3',\n",
       " 'R_2aDA1p5jTh7PB4L': '3',\n",
       " 'R_3iL7Bb8TebV6SkA': '4',\n",
       " 'R_2CmqkAdOeUi1xWf': '2',\n",
       " 'R_2Yxqwd5stTWvXrk': '4',\n",
       " 'R_2EzMoayYkfTPTxQ': '3',\n",
       " 'R_2sb6OcFJmuKJ3m6': '4',\n",
       " 'R_OMZQRYd2WObyL7P': '4',\n",
       " 'R_2wtxKfYyIShBPXa': '3',\n",
       " 'R_1hZojnC9z2Nxa7I': '4',\n",
       " 'R_3n7tqCPfKQNxjXO': '4',\n",
       " 'R_11jAOMxh4DNhvcL': '3',\n",
       " 'R_2Sov2cBkyMqFEFs': '4',\n",
       " 'R_3nOUkHgeEqWnvH4': '4',\n",
       " 'R_2TpE8g3WY5d3G2R': '4',\n",
       " 'R_1I5fjYH6ZxS4xGU': '3',\n",
       " 'R_1KwfYSjA9xlEUjy': '4',\n",
       " 'R_24w7C8DRPnOEcnk': '2',\n",
       " 'R_3Gx1GY1AUOZ4f7j': '2',\n",
       " 'R_3kIoYaOJVJvQD8a': '4',\n",
       " 'R_3egKPzDAMgX2Av9': '5',\n",
       " 'R_3Rgdw7o880c9ydG': '4',\n",
       " 'R_114rEkHDNspQ3JC': '2',\n",
       " 'R_2qpZnb8MlrnYaFt': '4',\n",
       " 'R_1jSUHWnIvCbSEC8': '4',\n",
       " 'R_2SoBmdm3On3ioGt': '2',\n",
       " 'R_33jaBSF47EEmPxU': '4',\n",
       " 'R_2cqjoxPx0jzjqLo': '4',\n",
       " 'R_1d9P1uy2X1IrWrc': '4',\n",
       " 'R_2bK37W2qk8QFBzN': '4',\n",
       " 'R_1jlWUEAMk1aS2bo': '4',\n",
       " 'R_1oBxoCbqn4BHHEn': '4',\n",
       " 'R_RtnW9ZeL6MDTh29': '4',\n",
       " 'R_eJKR5yL1ILNu0UN': '4',\n",
       " 'R_2aeGUhy6Fa9x3nq': '4',\n",
       " 'R_4TNu2uTx1STSU3D': '5',\n",
       " 'R_3KJzaL4er8c3hAS': '4',\n",
       " 'R_2eWDlJMbtaYZOUR': '3',\n",
       " 'R_8vq1pROw2cswoTf': '4',\n",
       " 'R_3k7Io0idB7CFvMr': '4',\n",
       " 'R_1CqDynml5s2RS6a': '4',\n",
       " 'R_2Ys1uzo0fsHOWZg': '4',\n",
       " 'R_3L5tzp9Tc8p2bMF': '4',\n",
       " 'R_u238jJfGuoeM86d': '4',\n",
       " 'R_1q3eydK8QAsaQNd': '3',\n",
       " 'R_C1yl2cvNtZ5ikSZ': '4',\n",
       " 'R_5pARfabe2Pbo11L': '4',\n",
       " 'R_3EMCa4QDE8ZDLE6': '3',\n",
       " 'R_1gU8gsW6rVxZzhg': '5',\n",
       " 'R_1OpYubHaJsD4lIY': '4',\n",
       " 'R_1rjESRjZEyPCI6l': '3',\n",
       " 'R_pboQGhbeWY1xayl': '2',\n",
       " 'R_27jpdnnanaBFJSx': '4',\n",
       " 'R_1Lp302uc28P303n': '2',\n",
       " 'R_OJ3AK4MupHW6yvD': '2',\n",
       " 'R_aUZZC2ZmHYgwdkR': '4',\n",
       " 'R_2rhW53rkP2ZaxHM': '4',\n",
       " 'R_1KpdqL2LgzKWmiO': '3',\n",
       " 'R_2dj36qJdnWTyQMB': '4',\n",
       " 'R_3Nxp1reCwfvOz3v': '3',\n",
       " 'R_vTaGQ1WNxaTxVnz': '4',\n",
       " 'R_2419ty1sBWmzaEU': '4',\n",
       " 'R_2bHU5ch7xKbXGpt': '4',\n",
       " 'R_2VygeXSJRiMjyvA': '3',\n",
       " 'R_3fPiI5WKXnP7fp5': '2',\n",
       " 'R_2aBrjBFb1MwMHLP': '3',\n",
       " 'R_UVWX3dpZYOCVlT3': '4',\n",
       " 'R_273einiUFOGXkdi': '4',\n",
       " 'R_21APst0ooiR2GzS': '4',\n",
       " 'R_3M4Ol1inUW5Sa0e': '4',\n",
       " 'R_3szTzjkvvlDGGv3': '4',\n",
       " 'R_1jADOIo0DTWKNXh': '4',\n",
       " 'R_3EzmOFaYtdX6OO2': '1',\n",
       " 'R_RfRi0agglxpZv0Z': '4',\n",
       " 'R_ePP1jIArvi6eRfr': '4',\n",
       " 'R_eVCzsIGS7fbSda1': '4',\n",
       " 'R_1FEYWSMtThVCp6x': '3',\n",
       " 'R_2EbdmTqDlxp9lhn': '4'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually check to see if there are issues; any value that doesn't make sense can be re-generated\n",
    "# data.loc[data['ResponseId'] == 'R_1I5liwuUZD8LpgM']\n",
    "response2exp_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T18:08:01.580597Z",
     "start_time": "2023-08-02T18:08:01.575610Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def convert(val):\n",
    "    try:\n",
    "        return float(val)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "data['gpt3.5'] = data['ResponseId'].apply(lambda rid : convert(response2exp_rating[rid]))\n",
    "data['gpt3.5_q1'] = data['ResponseId'].apply(lambda rid : convert(response2intro_q1[rid]))\n",
    "data['gpt3.5_q2'] = data['ResponseId'].apply(lambda rid : convert(response2intro_q2[rid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T18:08:08.424570Z",
     "start_time": "2023-08-02T18:08:08.417006Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"/Users/Lara/Dropbox/LanguageGender/Data/Advocates/Cleaned/gpt3half_community.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T16:59:56.470362Z",
     "start_time": "2023-08-02T16:59:56.470352Z"
    }
   },
   "outputs": [],
   "source": [
    "## If the data measures accountability, merge with other datasets on accountability before output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T01:14:59.602627Z",
     "start_time": "2023-08-02T01:14:59.588801Z"
    }
   },
   "outputs": [],
   "source": [
    "devon = pd.read_csv(\"/Users/Lara/Dropbox/LanguageGender/Data/Advocates/Cleaned/Rating_May 1_Devon.csv\")\n",
    "data = data.merge(devon[['creative', 'ResponseId']], on='ResponseId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T01:15:01.892083Z",
     "start_time": "2023-08-02T01:15:01.868654Z"
    }
   },
   "outputs": [],
   "source": [
    "kara = pd.read_csv(\"/Users/Lara/Dropbox/LanguageGender/Data/Advocates/Cleaned/Embedding Distance/Embedding_Distance_Fixed_Stop.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T01:15:02.458616Z",
     "start_time": "2023-08-02T01:15:02.453316Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.merge(kara[['text.avg_dist', 'ResponseId']], on='ResponseId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T01:15:03.205639Z",
     "start_time": "2023-08-02T01:15:03.194753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt3.5</th>\n",
       "      <th>creative</th>\n",
       "      <th>text.avg_dist</th>\n",
       "      <th>mtld</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt3.5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.432569</td>\n",
       "      <td>0.090163</td>\n",
       "      <td>0.235401</td>\n",
       "      <td>-0.141679</td>\n",
       "      <td>0.365736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creative</th>\n",
       "      <td>0.432569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004998</td>\n",
       "      <td>0.317840</td>\n",
       "      <td>-0.266124</td>\n",
       "      <td>0.534427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text.avg_dist</th>\n",
       "      <td>0.090163</td>\n",
       "      <td>0.004998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.044884</td>\n",
       "      <td>0.272311</td>\n",
       "      <td>-0.124160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtld</th>\n",
       "      <td>0.235401</td>\n",
       "      <td>0.317840</td>\n",
       "      <td>-0.044884</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.334776</td>\n",
       "      <td>0.670968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td>-0.141679</td>\n",
       "      <td>-0.266124</td>\n",
       "      <td>0.272311</td>\n",
       "      <td>-0.334776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.590090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>0.365736</td>\n",
       "      <td>0.534427</td>\n",
       "      <td>-0.124160</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>-0.590090</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 gpt3.5  creative  text.avg_dist      mtld  perplexity  \\\n",
       "gpt3.5         1.000000  0.432569       0.090163  0.235401   -0.141679   \n",
       "creative       0.432569  1.000000       0.004998  0.317840   -0.266124   \n",
       "text.avg_dist  0.090163  0.004998       1.000000 -0.044884    0.272311   \n",
       "mtld           0.235401  0.317840      -0.044884  1.000000   -0.334776   \n",
       "perplexity    -0.141679 -0.266124       0.272311 -0.334776    1.000000   \n",
       "text_length    0.365736  0.534427      -0.124160  0.670968   -0.590090   \n",
       "\n",
       "               text_length  \n",
       "gpt3.5            0.365736  \n",
       "creative          0.534427  \n",
       "text.avg_dist    -0.124160  \n",
       "mtld              0.670968  \n",
       "perplexity       -0.590090  \n",
       "text_length       1.000000  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['gpt3.5', 'creative', 'text.avg_dist', 'mtld', 'perplexity',  'text_length', ]].corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T18:47:16.813726Z",
     "start_time": "2023-08-02T18:47:16.809636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['That community brings people together and encourages others. It is an investment in our surroundings as well as the future of the world around us.',\n",
       " \"I would say here at AT Metrics we've decided to highlight the importance of community, our new core value. We support our employees efforts in their communities and want to highlight your work. We want to see what you can do for your community - how can you help improve it?\",\n",
       " 'We are individuals but this is a way that we can use our unique talents to craft a story by each contributing a page.',\n",
       " 'Community is the ability to come together as a group and know that the people around you care about you and what happens to you, and will do anything in their power to help you succeed - in the knowledge that they will be extended the same luxury in their hour of need.']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values(by='gpt3.5')['text'][-4:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T01:15:20.702005Z",
     "start_time": "2023-08-02T01:15:20.679077Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"/Users/Lara/Dropbox/LanguageGender/Data/Advocates/Cleaned/gpt3half_accountability.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T00:24:46.234216Z",
     "start_time": "2023-07-22T00:24:46.218967Z"
    }
   },
   "source": [
    "# Add Token Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T18:41:59.749959Z",
     "start_time": "2023-08-02T18:41:59.563064Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "data = pd.read_csv(\"/Users/Lara/Dropbox/LanguageGender/Data/Advocates/Cleaned/gpt3half_accountability.csv\")\n",
    "data['q1_text_length'] = data['Intro.Question.1'].apply(lambda t : len(nltk.word_tokenize(t)))\n",
    "data['q2_text_length'] = data['Intro.Question.2'].apply(lambda t : len(nltk.word_tokenize(t)))\n",
    "#data.to_csv(\"/Users/Lara/Dropbox/LanguageGender/Data/Advocates/Cleaned/gpt3half_accountability.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T19:06:25.422679Z",
     "start_time": "2023-08-02T19:06:25.347716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Purple']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/Lara/Dropbox/LanguageGender/Data/Advocates/Cleaned/gpt3half_speed.csv\")\n",
    "print(data['Attention.Check'].unique())\n",
    "\n",
    "data['q1_text_length'] = data['Intro.Question.1'].apply(lambda t : len(nltk.word_tokenize(t)))\n",
    "data['q2_text_length'] = data['Intro.Question.2'].apply(lambda t : len(nltk.word_tokenize(t)))\n",
    "data['exp_text_length'] = data['text'].apply(lambda t : len(nltk.word_tokenize(t)))\n",
    "#data.to_csv(\"/Users/Lara/Dropbox/LanguageGender/Data/Advocates/Cleaned/gpt3half_speed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T19:06:30.965264Z",
     "start_time": "2023-08-02T19:06:30.881399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Purple']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/Lara/Dropbox/LanguageGender/Data/Advocates/Cleaned/gpt3half_community.csv\")\n",
    "print(data['Attention.Check'].unique())\n",
    "\n",
    "data['q1_text_length'] = data['Intro.Question.1'].apply(lambda t : len(nltk.word_tokenize(t)))\n",
    "data['q2_text_length'] = data['Intro.Question.2'].apply(lambda t : len(nltk.word_tokenize(t)))\n",
    "data['exp_text_length'] = data['text'].apply(lambda t : len(nltk.word_tokenize(t)))\n",
    "#data.to_csv(\"/Users/Lara/Dropbox/LanguageGender/Data/Advocates/Cleaned/gpt3half_community.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T19:06:02.717155Z",
     "start_time": "2023-08-02T19:06:02.713492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Purple'], dtype=object)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
